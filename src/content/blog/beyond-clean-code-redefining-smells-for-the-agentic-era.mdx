---
title: "Beyond Clean Code: Redefining 'Smells' for the Agentic Era"
date: "2026-02-06"
description: "AI agents are writing more code than ever. But as the volume of automated commits grows, how do we identify the new breed of technical debt?"
tags: ["Engineering", "AI Agents", "System Design", "Technical Debt"]
category: "Engineering"
image_prompt: "A minimalist, dark-themed geometric composition. Interlocking isometric cubes representing code modules, with glowing circuit lines connecting them. Dark slate background with sharp neon teal accents. Professional, engineering-focused aesthetic."
---

We’ve spent decades refining what "good code" looks like for humans. From SOLID principles to Uncle Bob’s clean code, the goal was readability and maintainability. But as we shift toward a paradigm where AI agents—like those being built at Factory—are primary contributors to the codebase, the definition of a "code smell" is evolving.

My takeaway from the recent Q&A with Eno Reyes is straightforward: **Quality software still requires high-quality engineering, regardless of who (or what) writes the lines.**

### 1. The Challenge: Managing the Velocity of Technical Debt
The primary challenge isn't just "Can the AI write code?" It’s "Can the system survive the volume of code the AI generates?" 

In a traditional environment, technical debt accumulates through human shortcuts or shifting requirements. In an agentic environment, debt accumulates through **non-determinism and context drift.** If an agent lacks a "grounded" understanding of the existing architecture, it might solve a local problem (fixing a bug) while creating a global architectural violation (breaking a design pattern). 

We are moving from a world of "hand-crafted" code to "high-velocity automated" code. The scale problem here isn't just request latency; it’s the cognitive load required for a human to audit the sheer volume of agent-generated changes.

### 2. The Architecture: Designing for Agentic Observability
Building systems that accommodate AI agents requires shifting from static code analysis to dynamic evaluation loops. 

*   **Deterministic Guardrails:** Just as I integrated hardware sensors with FastAPI in the **Green Engine** project to ensure crop data stayed within logical bounds, AI systems need "grounding layers." You can't just let an agent hallucinate an API endpoint; the system design must include schema-first development where the agent is forced to adhere to strict types.
*   **The Self-Correction Loop:** Reyes highlights the need for agents to "smell" their own mistakes. This mirrors the **Event-Driven** pattern. An agent shouldn't just push code; it should trigger a suite of automated tests, analyze the failures, and iterate before a human ever sees a PR.
*   **Agentic Modularization:** We need to move away from "monolithic" prompts. Small, specialized agents acting on specific microservices are easier to monitor than one "god-agent" trying to understand a 10-million-line repository.

### 3. Takeaway: Strategy Over Syntax
My take is this: **Prompt engineering is a band-aid; System Design is the cure.**

The "smells" Reyes discusses—like agents creating redundant logic or failing to use existing utilities—are symptoms of poor system grounding. For those of us building the next generation of platforms, the lesson is clear: 

Don't just optimize for how fast an agent can write code. Optimize for the **Systemic ROI**. A thousand lines of code generated in seconds is a liability if it takes three hours of senior engineering time to debug. 

If it doesn't solve a user problem without breaking the system, it's just expensive noise. Whether you’re building a two-sided marketplace like my **Collaborative Ecosystem** or an enterprise AI agent, the engineering reality remains: data and structure trump hype every time.